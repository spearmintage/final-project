{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "goal:\n",
    "\n",
    "- use librosa on 1000 audio files and/or 50 class folders minimum\n",
    "- store information in a dataframe (excluding actual file data for now)\n",
    "  - folder name, file name, sampling rate, data length, file length, file size(?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-15T01:26:16.971176Z",
     "iopub.status.busy": "2025-12-15T01:26:16.971052Z",
     "iopub.status.idle": "2025-12-15T01:26:23.912954Z",
     "shell.execute_reply": "2025-12-15T01:26:23.912258Z",
     "shell.execute_reply.started": "2025-12-15T01:26:16.971162Z"
    },
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchaudio\n",
    "import copy\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.simplefilter(action='ignore', category=pd.errors.SettingWithCopyWarning)\n",
    "warnings.simplefilter(action='ignore', category=UserWarning)\n",
    "\n",
    "from tqdm import tqdm\n",
    "from IPython.display import Audio\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "from math import floor\n",
    "\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-15T01:26:23.913762Z",
     "iopub.status.busy": "2025-12-15T01:26:23.913509Z",
     "iopub.status.idle": "2025-12-15T01:26:23.922193Z",
     "shell.execute_reply": "2025-12-15T01:26:23.921734Z",
     "shell.execute_reply.started": "2025-12-15T01:26:23.913747Z"
    },
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "def reset_seed():\n",
    "    torch.manual_seed(1368)\n",
    "    random.seed(1368)\n",
    "    np.random.seed(1368)\n",
    "\n",
    "reset_seed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-15T01:26:23.923220Z",
     "iopub.status.busy": "2025-12-15T01:26:23.923085Z",
     "iopub.status.idle": "2025-12-15T01:26:24.064369Z",
     "shell.execute_reply": "2025-12-15T01:26:24.063844Z",
     "shell.execute_reply.started": "2025-12-15T01:26:23.923208Z"
    },
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8589410304\n",
      "cuda\n",
      "NVIDIA GeForce RTX 3070 Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "for i in range(torch.cuda.device_count()):\n",
    "   print(torch.cuda.get_device_properties(i).total_memory)\n",
    "\n",
    "print(device)\n",
    "print(torch.cuda.get_device_name())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "def get_random_folders_filtered(base_dir: str, split_interval_secs: float, sample_rate: int = 32000, total_folders: int = 50, max_files_per_folder: int = -1, min_rating: float = 4.0):\n",
    "    # base_dir: directory of all the audio file folders\n",
    "    # split_interval_secs: the length of each sound clip when split up in a file.\n",
    "    #   - final dataframe will not contain any sound clips over/under this length\n",
    "    # sample_rate: sample rate of sound clips in hz\n",
    "    # total_folders: total folders to iterate through the files, given range of files per folder\n",
    "    # min_files_per_folder: minimum files to exist in the folder\n",
    "    # max_files_per_folder: maximum files to use inside the folder\n",
    "\n",
    "    folders = os.listdir(base_dir)\n",
    "    folder_count = 0\n",
    "    random.shuffle(folders)\n",
    "\n",
    "    # get the list of valid folders and files to analyse\n",
    "    folders = set()\n",
    "    lines = set([l.replace(\"\\n\", \"\") for l in open(f\"rating_thresholds_at_least_10_classes/min_rating_{int(min_rating * 2)}.txt\").readlines()])\n",
    "    for l in lines: folders.add(l.split(\"/\")[0])\n",
    "\n",
    "    folders = list(folders)\n",
    "    folder_count = 0\n",
    "    random.shuffle(folders)\n",
    "\n",
    "    # if there are less folders than those specified, view all folders instead of given amount\n",
    "    total_folders = min(len(folders), total_folders)\n",
    "    split_length = 10000000000000 # absurd number for future use\n",
    "\n",
    "    rows = []\n",
    "    \n",
    "    for folder in folders:\n",
    "        folder_path = base_dir + folder + \"/\"\n",
    "        valid_folder_files = []\n",
    "        # only iterate through the valid audio files\n",
    "        for file in os.listdir(folder_path):\n",
    "            if folder + \"/\" + file in lines:\n",
    "                valid_folder_files.append(folder_path + file)\n",
    "        random.shuffle(valid_folder_files)\n",
    "\n",
    "        if max_files_per_folder > 0:\n",
    "            valid_folder_files = valid_folder_files[:min(max_files_per_folder, len(valid_folder_files))]\n",
    "\n",
    "        # iterate through each file in the folder\n",
    "        for file_path in (progress_bar := tqdm(valid_folder_files)):\n",
    "            # load file data and resample to sample_rate if necessary\n",
    "            file_data, file_sample_rate_hz = torchaudio.load(uri=file_path, channels_first=True)\n",
    "            if file_sample_rate_hz != sample_rate:\n",
    "                file_data = torchaudio.functional.resample(file_data, orig_freq=file_sample_rate_hz, new_freq=sample_rate)\n",
    "\n",
    "            # convert all audio into mono (1 channel) if audio is stereo (2 channels)\n",
    "            if file_data.shape[0] == 2:\n",
    "                file_data = file_data.mean(dim=0)\n",
    "            else:\n",
    "                file_data = file_data.flatten()\n",
    "\n",
    "            # get total number of X second splits\n",
    "            total_splits = floor(len(file_data) / int(sample_rate * split_interval_secs))\n",
    "            \n",
    "            # convert file data into mel-spectrogram fourier transform for feeding into CNN\n",
    "            n_fft = 1024\n",
    "\n",
    "            mel_spec_transform = torchaudio.transforms.MelSpectrogram(sample_rate = sample_rate, power=2, n_fft=n_fft)\n",
    "            amp_to_db_transform = torchaudio.transforms.AmplitudeToDB(stype=\"amplitude\", top_db=80)\n",
    "            mel_spec_data_db = amp_to_db_transform(mel_spec_transform(file_data))\n",
    "            \n",
    "            # if file is at least X seconds.\n",
    "            if total_splits >= 1:\n",
    "                split_length = min(mel_spec_data_db.shape[1] // total_splits, split_length)\n",
    "                mel_spec_splits = np.arange(0, mel_spec_data_db.shape[1], split_length)\n",
    "                for i in range(len(mel_spec_splits) - 1):\n",
    "                    start = mel_spec_splits[i]\n",
    "                    end = mel_spec_splits[i + 1]\n",
    "\n",
    "                    mel_spec_split = mel_spec_data_db[:, start:end]\n",
    "\n",
    "                    row = {}\n",
    "                    row[\"folder\"] = folder\n",
    "                    row[\"file\"] = file_path.split(\"/\")[-1]\n",
    "                    row[\"mel_spec\"] = mel_spec_split\n",
    "                    row[\"mel_spec_shape\"] = mel_spec_split.shape\n",
    "\n",
    "                rows.append(row)\n",
    "\n",
    "            progress_bar.set_description(f\"Folder {folder_count + 1}/{total_folders} - {folder}\")\n",
    "\n",
    "        # end loop if total_folders has been reached\n",
    "        folder_count += 1\n",
    "        if folder_count >= total_folders: break\n",
    "\n",
    "    # trim the ends of some mel spectrograms because of stupid floating point nonsense\n",
    "    for row in rows:\n",
    "        if row[\"mel_spec_shape\"][1] != split_length:\n",
    "            row[\"mel_spec\"] = row[\"mel_spec\"][:, :split_length]\n",
    "            row[\"mel_spec_shape\"] = row[\"mel_spec\"].shape\n",
    "\n",
    "    return pd.DataFrame(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-15T01:26:24.078144Z",
     "iopub.status.busy": "2025-12-15T01:26:24.078005Z",
     "iopub.status.idle": "2025-12-15T01:26:54.511821Z",
     "shell.execute_reply": "2025-12-15T01:26:54.511387Z",
     "shell.execute_reply.started": "2025-12-15T01:26:24.078131Z"
    },
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Folder 1/400 - easpho: 100%|██████████| 15/15 [00:01<00:00, 11.06it/s]\n",
      "Folder 2/400 - brubru1: 100%|██████████| 10/10 [00:00<00:00, 26.50it/s]\n",
      "Folder 3/400 - blsspa1: 100%|██████████| 21/21 [00:01<00:00, 12.40it/s]\n",
      "Folder 4/400 - carchi: 100%|██████████| 32/32 [00:02<00:00, 12.25it/s]\n",
      "Folder 5/400 - yebbab1: 100%|██████████| 14/14 [00:00<00:00, 14.98it/s]\n",
      "Folder 6/400 - calqua: 100%|██████████| 34/34 [00:04<00:00,  7.59it/s]\n",
      "Folder 7/400 - grycat: 100%|██████████| 56/56 [00:09<00:00,  5.69it/s]\n",
      "Folder 8/400 - abhori1: 100%|██████████| 25/25 [00:02<00:00, 11.34it/s]\n",
      "Folder 9/400 - spvear1: 100%|██████████| 30/30 [00:03<00:00,  7.70it/s]\n",
      "Folder 10/400 - caster1: 100%|██████████| 44/44 [00:03<00:00, 11.67it/s]\n",
      "Folder 11/400 - prowar: 100%|██████████| 17/17 [00:09<00:00,  1.82it/s]\n",
      "Folder 12/400 - yehcar1: 100%|██████████| 36/36 [00:03<00:00, 10.23it/s]\n",
      "Folder 13/400 - renpha: 100%|██████████| 18/18 [00:04<00:00,  4.43it/s]\n",
      "Folder 14/400 - arcter: 100%|██████████| 82/82 [00:08<00:00,  9.79it/s]\n",
      "Folder 15/400 - snobun: 100%|██████████| 31/31 [00:05<00:00,  5.91it/s]\n",
      "Folder 16/400 - gretin1: 100%|██████████| 15/15 [00:02<00:00,  5.54it/s]\n",
      "Folder 17/400 - easmea: 100%|██████████| 53/53 [00:06<00:00,  7.58it/s]\n",
      "Folder 18/400 - grhowl: 100%|██████████| 97/97 [00:15<00:00,  6.14it/s]\n",
      "Folder 19/400 - treswa: 100%|██████████| 18/18 [00:04<00:00,  4.42it/s]\n",
      "Folder 20/400 - rubrob: 100%|██████████| 15/15 [00:01<00:00, 11.89it/s]\n",
      "Folder 21/400 - brwowl1: 100%|██████████| 19/19 [00:03<00:00,  5.40it/s]\n",
      "Folder 22/400 - yebapa1: 100%|██████████| 16/16 [00:00<00:00, 17.36it/s]\n",
      "Folder 23/400 - rubpep1: 100%|██████████| 70/70 [00:07<00:00,  9.12it/s]\n",
      "Folder 24/400 - buwwar: 100%|██████████| 11/11 [00:02<00:00,  4.49it/s]\n",
      "Folder 25/400 - commyn: 100%|██████████| 66/66 [00:10<00:00,  6.27it/s]\n",
      "Folder 26/400 - rebfir2: 100%|██████████| 10/10 [00:00<00:00, 13.46it/s]\n",
      "Folder 27/400 - bkbwar: 100%|██████████| 19/19 [00:04<00:00,  3.82it/s]\n",
      "Folder 28/400 - rorpar: 100%|██████████| 129/129 [00:10<00:00, 11.94it/s]\n",
      "Folder 29/400 - ashdro1: 100%|██████████| 29/29 [00:02<00:00, 11.70it/s]\n",
      "Folder 30/400 - litegr: 100%|██████████| 127/127 [00:05<00:00, 23.48it/s]\n",
      "Folder 31/400 - grewar3: 100%|██████████| 82/82 [00:14<00:00,  5.62it/s]\n",
      "Folder 32/400 - comros: 100%|██████████| 102/102 [00:12<00:00,  8.08it/s]\n",
      "Folder 33/400 - litspi1: 100%|██████████| 42/42 [00:03<00:00, 10.73it/s]\n",
      "Folder 34/400 - chbwre1: 100%|██████████| 46/46 [00:07<00:00,  5.79it/s]\n",
      "Folder 35/400 - creoro1: 100%|██████████| 26/26 [00:03<00:00,  8.24it/s]\n",
      "Folder 36/400 - leasan: 100%|██████████| 18/18 [00:01<00:00, 13.20it/s]\n",
      "Folder 37/400 - egygoo: 100%|██████████| 46/46 [00:03<00:00, 15.32it/s]\n",
      "Folder 38/400 - whwdov: 100%|██████████| 16/16 [00:01<00:00, 10.44it/s]\n",
      "Folder 39/400 - goftyr1: 100%|██████████| 27/27 [00:02<00:00, 11.38it/s]\n",
      "Folder 40/400 - cohmar1: 100%|██████████| 115/115 [00:10<00:00, 10.88it/s]\n",
      "Folder 41/400 - gartro1: 100%|██████████| 11/11 [00:01<00:00,  8.08it/s]\n",
      "Folder 42/400 - bulori: 100%|██████████| 13/13 [00:01<00:00,  8.31it/s]\n",
      "Folder 43/400 - socfly1: 100%|██████████| 45/45 [00:04<00:00, 10.31it/s]\n",
      "Folder 44/400 - afpwag1: 100%|██████████| 29/29 [00:02<00:00, 11.55it/s]\n",
      "Folder 45/400 - bkpwar: 100%|██████████| 22/22 [00:04<00:00,  4.53it/s]\n",
      "Folder 46/400 - putbab1: 100%|██████████| 64/64 [00:05<00:00, 12.71it/s]\n",
      "Folder 47/400 - brnhao1: 100%|██████████| 31/31 [00:02<00:00, 12.96it/s]\n",
      "Folder 48/400 - mawthr1: 100%|██████████| 18/18 [00:01<00:00, 10.27it/s]\n",
      "Folder 49/400 - veery: 100%|██████████| 21/21 [00:04<00:00,  4.95it/s]\n",
      "Folder 50/400 - subbus1: 100%|██████████| 14/14 [00:00<00:00, 16.00it/s]\n",
      "Folder 51/400 - grecor: 100%|██████████| 44/44 [00:04<00:00, 10.52it/s]\n",
      "Folder 52/400 - lessts1: 100%|██████████| 11/11 [00:00<00:00, 15.75it/s]\n",
      "Folder 53/400 - bkbmag1: 100%|██████████| 13/13 [00:01<00:00,  6.93it/s]\n",
      "Folder 54/400 - ashwoo2: 100%|██████████| 11/11 [00:00<00:00, 14.63it/s]\n",
      "Folder 55/400 - tafpri1: 100%|██████████| 29/29 [00:01<00:00, 17.31it/s]\n",
      "Folder 56/400 - mouwar: 100%|██████████| 17/17 [00:04<00:00,  4.11it/s]\n",
      "Folder 57/400 - reevir1: 100%|██████████| 35/35 [00:06<00:00,  5.74it/s]\n",
      "Folder 58/400 - purfin: 100%|██████████| 14/14 [00:02<00:00,  6.56it/s]\n",
      "Folder 59/400 - wrenti: 100%|██████████| 32/32 [00:03<00:00,  8.61it/s]\n",
      "Folder 60/400 - hergul: 100%|██████████| 76/76 [00:06<00:00, 11.46it/s]\n",
      "Folder 61/400 - amtspa: 100%|██████████| 16/16 [00:01<00:00,  9.33it/s]\n",
      "Folder 62/400 - woothr: 100%|██████████| 34/34 [00:11<00:00,  2.96it/s]\n",
      "Folder 63/400 - sincis1: 100%|██████████| 13/13 [00:00<00:00, 15.38it/s]\n",
      "Folder 64/400 - yebori1: 100%|██████████| 21/21 [00:01<00:00, 11.33it/s]\n",
      "Folder 65/400 - tromoc: 100%|██████████| 28/28 [00:03<00:00,  7.66it/s]\n",
      "Folder 66/400 - gbbgul: 100%|██████████| 27/27 [00:01<00:00, 16.18it/s]\n",
      "Folder 67/400 - soulap1: 100%|██████████| 69/69 [00:07<00:00,  9.65it/s]\n",
      "Folder 68/400 - gnttow: 100%|██████████| 35/35 [00:06<00:00,  5.81it/s]\n",
      "Folder 69/400 - blbthr1: 100%|██████████| 15/15 [00:02<00:00,  7.21it/s]\n",
      "Folder 70/400 - bncfly: 100%|██████████| 42/42 [00:07<00:00,  5.56it/s]\n",
      "Folder 71/400 - whbwat1: 100%|██████████| 43/43 [00:05<00:00,  8.22it/s]\n",
      "Folder 72/400 - comgre: 100%|██████████| 161/161 [00:10<00:00, 14.75it/s]\n",
      "Folder 73/400 - rebnut: 100%|██████████| 29/29 [00:03<00:00,  8.13it/s]\n",
      "Folder 74/400 - cedwax: 100%|██████████| 17/17 [00:01<00:00, 10.38it/s]\n",
      "Folder 75/400 - labwoo: 100%|██████████| 22/22 [00:01<00:00, 13.70it/s]\n",
      "Folder 76/400 - darbar1: 100%|██████████| 13/13 [00:01<00:00, 12.60it/s]\n",
      "Folder 77/400 - wessan: 100%|██████████| 13/13 [00:01<00:00,  8.00it/s]\n",
      "Folder 78/400 - yebfly: 100%|██████████| 14/14 [00:01<00:00,  7.17it/s]\n",
      "Folder 79/400 - mallar3: 100%|██████████| 138/138 [00:17<00:00,  7.69it/s]\n",
      "Folder 80/400 - rempar: 100%|██████████| 19/19 [00:01<00:00,  9.70it/s]\n",
      "Folder 81/400 - tibfly3: 100%|██████████| 34/34 [00:03<00:00, 10.19it/s]\n",
      "Folder 82/400 - greegr: 100%|██████████| 75/75 [00:03<00:00, 22.68it/s]\n",
      "Folder 83/400 - clcrob: 100%|██████████| 39/39 [00:05<00:00,  7.26it/s]\n",
      "Folder 84/400 - gloibi: 100%|██████████| 40/40 [00:01<00:00, 23.01it/s]\n",
      "Folder 85/400 - acowoo: 100%|██████████| 29/29 [00:03<00:00,  8.23it/s]\n",
      "Folder 86/400 - gargan: 100%|██████████| 40/40 [00:01<00:00, 20.57it/s]\n",
      "Folder 87/400 - brodro1: 100%|██████████| 30/30 [00:03<00:00,  9.24it/s]\n",
      "Folder 88/400 - thbwar1: 100%|██████████| 35/35 [00:09<00:00,  3.70it/s]\n",
      "Folder 89/400 - bkctch1: 100%|██████████| 15/15 [00:01<00:00, 11.60it/s]\n",
      "Folder 90/400 - y00475: 100%|██████████| 43/43 [00:03<00:00, 13.86it/s]\n",
      "Folder 91/400 - baisan: 100%|██████████| 15/15 [00:01<00:00,  8.96it/s]\n",
      "Folder 92/400 - kenplo1: 100%|██████████| 80/80 [00:04<00:00, 18.52it/s]\n",
      "Folder 93/400 - glwgul: 100%|██████████| 19/19 [00:02<00:00,  7.57it/s]\n",
      "Folder 94/400 - sancra: 100%|██████████| 35/35 [00:06<00:00,  5.54it/s]\n",
      "Folder 95/400 - roahaw: 100%|██████████| 75/75 [00:51<00:00,  1.47it/s]\n",
      "Folder 96/400 - plhpar1: 100%|██████████| 13/13 [00:00<00:00, 14.26it/s]\n",
      "Folder 97/400 - caltow: 100%|██████████| 27/27 [00:03<00:00,  8.62it/s]\n",
      "Folder 98/400 - ocbfly1: 100%|██████████| 10/10 [00:01<00:00,  7.90it/s]\n",
      "Folder 99/400 - trogna1: 100%|██████████| 28/28 [00:01<00:00, 14.21it/s]\n",
      "Folder 100/400 - batpig1: 100%|██████████| 11/11 [00:01<00:00,  8.55it/s]\n",
      "Folder 101/400 - rudtur: 100%|██████████| 52/52 [00:04<00:00, 11.54it/s]\n",
      "Folder 102/400 - sinwre1: 100%|██████████| 24/24 [00:02<00:00,  8.12it/s]\n",
      "Folder 103/400 - saffin: 100%|██████████| 35/35 [00:03<00:00,  9.92it/s]\n",
      "Folder 104/400 - grethr1: 100%|██████████| 55/55 [00:07<00:00,  7.77it/s]\n",
      "Folder 105/400 - heswoo1: 100%|██████████| 10/10 [00:00<00:00, 16.51it/s]\n",
      "Folder 106/400 - piekin1: 100%|██████████| 18/18 [00:00<00:00, 24.82it/s]\n",
      "Folder 107/400 - pursun3: 100%|██████████| 19/19 [00:01<00:00, 15.41it/s]\n",
      "Folder 108/400 - whbtre1: 100%|██████████| 10/10 [00:00<00:00, 10.15it/s]\n",
      "Folder 109/400 - linspa: 100%|██████████| 36/36 [00:06<00:00,  5.83it/s]\n",
      "Folder 110/400 - compea: 100%|██████████| 24/24 [00:00<00:00, 24.22it/s]\n",
      "Folder 111/400 - whbman1: 100%|██████████| 33/33 [00:03<00:00, 10.06it/s]\n",
      "Folder 112/400 - bushti: 100%|██████████| 29/29 [00:02<00:00, 11.41it/s]\n",
      "Folder 113/400 - tuftit: 100%|██████████| 42/42 [00:03<00:00, 10.62it/s]\n",
      "Folder 114/400 - rocwre: 100%|██████████| 13/13 [00:03<00:00,  3.97it/s]\n",
      "Folder 115/400 - sander: 100%|██████████| 34/34 [00:01<00:00, 18.93it/s]\n",
      "Folder 116/400 - whcbar1: 100%|██████████| 28/28 [00:01<00:00, 17.77it/s]\n",
      "Folder 117/400 - gamqua: 100%|██████████| 20/20 [00:03<00:00,  5.32it/s]\n",
      "Folder 118/400 - ducfly: 100%|██████████| 53/53 [00:05<00:00,  9.83it/s]\n",
      "Folder 119/400 - cliswa: 100%|██████████| 26/26 [00:02<00:00,  9.14it/s]\n",
      "Folder 120/400 - blakit1: 100%|██████████| 50/50 [00:03<00:00, 12.74it/s]\n",
      "Folder 121/400 - cangoo: 100%|██████████| 80/80 [00:07<00:00, 10.95it/s]\n",
      "Folder 122/400 - houcro1: 100%|██████████| 53/53 [00:03<00:00, 14.25it/s]\n",
      "Folder 123/400 - wesmea: 100%|██████████| 60/60 [00:09<00:00,  6.27it/s]\n",
      "Folder 124/400 - comyel: 100%|██████████| 78/78 [00:11<00:00,  6.72it/s]\n",
      "Folder 125/400 - compau: 100%|██████████| 105/105 [00:14<00:00,  7.05it/s]\n",
      "Folder 126/400 - jabwar: 100%|██████████| 23/23 [00:06<00:00,  3.33it/s]\n",
      "Folder 127/400 - combuz1: 100%|██████████| 130/130 [00:14<00:00,  8.79it/s]\n",
      "Folder 128/400 - rehbar1: 100%|██████████| 11/11 [00:00<00:00, 20.38it/s]\n",
      "Folder 129/400 - dafbab1: 100%|██████████| 11/11 [00:00<00:00, 19.05it/s]\n",
      "Folder 130/400 - blaplo1: 100%|██████████| 14/14 [00:01<00:00, 11.18it/s]\n",
      "Folder 131/400 - obnthr1: 100%|██████████| 45/45 [00:06<00:00,  6.99it/s]\n",
      "Folder 132/400 - wbwwre1: 100%|██████████| 91/91 [00:10<00:00,  8.91it/s]\n",
      "Folder 133/400 - lesyel: 100%|██████████| 29/29 [00:02<00:00, 12.42it/s]\n",
      "Folder 134/400 - sltred: 100%|██████████| 51/51 [00:04<00:00, 10.22it/s]\n",
      "Folder 135/400 - casfin: 100%|██████████| 13/13 [00:01<00:00,  7.42it/s]\n",
      "Folder 136/400 - reccor: 100%|██████████| 10/10 [00:00<00:00, 13.91it/s]\n",
      "Folder 137/400 - sumtan: 100%|██████████| 40/40 [00:06<00:00,  6.44it/s]\n",
      "Folder 138/400 - ratcis1: 100%|██████████| 49/49 [00:03<00:00, 13.38it/s]\n",
      "Folder 139/400 - grefri: 100%|██████████| 10/10 [00:02<00:00,  4.86it/s]\n",
      "Folder 140/400 - reftin1: 100%|██████████| 10/10 [00:01<00:00,  8.26it/s]\n",
      "Folder 141/400 - cohcuc1: 100%|██████████| 23/23 [00:03<00:00,  6.37it/s]\n",
      "Folder 142/400 - phaino: 100%|██████████| 12/12 [00:02<00:00,  4.72it/s]\n",
      "Folder 143/400 - comkin1: 100%|██████████| 121/121 [00:10<00:00, 11.55it/s]\n",
      "Folder 144/400 - easblu: 100%|██████████| 17/17 [00:02<00:00,  8.32it/s]\n",
      "Folder 145/400 - spodov: 100%|██████████| 30/30 [00:03<00:00,  9.40it/s]\n",
      "Folder 146/400 - apapan: 100%|██████████| 12/12 [00:02<00:00,  4.76it/s]\n",
      "Folder 147/400 - rbsrob1: 100%|██████████| 58/58 [00:06<00:00,  9.56it/s]\n",
      "Folder 148/400 - brant: 100%|██████████| 40/40 [00:05<00:00,  7.31it/s]\n",
      "Folder 149/400 - gbwwre1: 100%|██████████| 198/198 [00:25<00:00,  7.86it/s]\n",
      "Folder 150/400 - scbwre1: 100%|██████████| 31/31 [00:05<00:00,  6.00it/s]\n",
      "Folder 151/400 - chcant2: 100%|██████████| 66/66 [00:09<00:00,  6.60it/s]\n",
      "Folder 152/400 - emedov2: 100%|██████████| 16/16 [00:01<00:00, 11.57it/s]\n",
      "Folder 153/400 - amekes: 100%|██████████| 20/20 [00:02<00:00,  8.25it/s]\n",
      "Folder 154/400 - gyhkin1: 100%|██████████| 16/16 [00:00<00:00, 18.13it/s]\n",
      "Folder 155/400 - lobcur: 100%|██████████| 27/27 [00:04<00:00,  6.74it/s]\n",
      "Folder 156/400 - sttwoo1: 100%|██████████| 14/14 [00:01<00:00, 11.30it/s]\n",
      "Folder 157/400 - gockin: 100%|██████████| 43/43 [00:06<00:00,  7.00it/s]\n",
      "Folder 158/400 - linwoo1: 100%|██████████| 29/29 [00:02<00:00, 10.72it/s]\n",
      "Folder 159/400 - junowl1: 100%|██████████| 20/20 [00:01<00:00, 11.22it/s]\n",
      "Folder 160/400 - blrwar1: 100%|██████████| 115/115 [01:15<00:00,  1.53it/s]\n",
      "Folder 161/400 - hadibi1: 100%|██████████| 40/40 [00:02<00:00, 16.89it/s]\n",
      "Folder 162/400 - whfpar1: 100%|██████████| 15/15 [00:02<00:00,  5.24it/s]\n",
      "Folder 163/400 - amered: 100%|██████████| 42/42 [00:05<00:00,  8.05it/s]\n",
      "Folder 164/400 - insowl1: 100%|██████████| 11/11 [00:00<00:00, 12.39it/s]\n",
      "Folder 165/400 - bktspa: 100%|██████████| 26/26 [00:05<00:00,  4.89it/s]\n",
      "Folder 166/400 - prawar: 100%|██████████| 15/15 [00:05<00:00,  2.52it/s]\n",
      "Folder 167/400 - rutjac1: 100%|██████████| 35/35 [00:02<00:00, 12.65it/s]\n",
      "Folder 168/400 - grbeat1: 100%|██████████| 15/15 [00:00<00:00, 20.24it/s]\n",
      "Folder 169/400 - comtai1: 100%|██████████| 78/78 [00:06<00:00, 11.59it/s]\n",
      "Folder 170/400 - nutman: 100%|██████████| 18/18 [00:01<00:00, 12.29it/s]\n",
      "Folder 171/400 - norpin: 100%|██████████| 13/13 [00:01<00:00, 12.30it/s]\n",
      "Folder 172/400 - lblwar1: 100%|██████████| 31/31 [00:02<00:00, 11.84it/s]\n",
      "Folder 173/400 - fepowl: 100%|██████████| 63/63 [00:07<00:00,  8.63it/s]\n",
      "Folder 174/400 - brnjay: 100%|██████████| 23/23 [00:02<00:00,  9.57it/s]\n",
      "Folder 175/400 - normoc: 100%|██████████| 84/84 [00:19<00:00,  4.30it/s]\n",
      "Folder 176/400 - mouela1: 100%|██████████| 15/15 [00:01<00:00, 10.65it/s]\n",
      "Folder 177/400 - yertin1: 100%|██████████| 10/10 [00:00<00:00, 12.03it/s]\n",
      "Folder 178/400 - robgro: 100%|██████████| 18/18 [00:02<00:00,  7.41it/s]\n",
      "Folder 179/400 - junbab2: 100%|██████████| 31/31 [00:03<00:00,  9.70it/s]\n",
      "Folder 180/400 - andsol1: 100%|██████████| 54/54 [00:07<00:00,  7.14it/s]\n",
      "Folder 181/400 - somgre1: 100%|██████████| 38/38 [00:03<00:00, 11.78it/s]\n",
      "Folder 182/400 - ruftre2: 100%|██████████| 47/47 [00:04<00:00, 11.74it/s]\n",
      "Folder 183/400 - gryhaw2: 100%|██████████| 13/13 [00:01<00:00, 11.66it/s]\n",
      "Folder 184/400 - wesant1: 100%|██████████| 10/10 [00:00<00:00, 13.47it/s]\n",
      "Folder 185/400 - canwar: 100%|██████████| 20/20 [00:02<00:00,  7.02it/s]\n",
      "Folder 186/400 - slcbou1: 100%|██████████| 16/16 [00:01<00:00, 12.62it/s]\n",
      "Folder 187/400 - eubeat1: 100%|██████████| 96/96 [00:09<00:00,  9.77it/s]\n",
      "Folder 188/400 - brcful1: 100%|██████████| 23/23 [00:02<00:00, 11.31it/s]\n",
      "Folder 189/400 - grcfly: 100%|██████████| 23/23 [00:02<00:00,  8.19it/s]\n",
      "Folder 190/400 - lobgna5: 100%|██████████| 56/56 [00:05<00:00,  9.72it/s]\n",
      "Folder 191/400 - commoo3: 100%|██████████| 123/123 [00:06<00:00, 20.29it/s]\n",
      "Folder 192/400 - grbcam1: 100%|██████████| 21/21 [00:01<00:00, 15.18it/s]\n",
      "Folder 193/400 - reedov1: 100%|██████████| 11/11 [00:00<00:00, 20.90it/s]\n",
      "Folder 194/400 - pingro: 100%|██████████| 12/12 [00:01<00:00,  7.30it/s]\n",
      "Folder 195/400 - lesgre1: 100%|██████████| 22/22 [00:02<00:00,  9.85it/s]\n",
      "Folder 196/400 - forwag1: 100%|██████████| 13/13 [00:00<00:00, 13.02it/s]\n",
      "Folder 197/400 - comfla1: 100%|██████████| 11/11 [00:00<00:00, 17.09it/s]\n",
      "Folder 198/400 - pabspi1: 100%|██████████| 41/41 [00:04<00:00,  8.95it/s]\n",
      "Folder 199/400 - lobdow: 100%|██████████| 24/24 [00:01<00:00, 15.01it/s]\n",
      "Folder 200/400 - ccbfin: 100%|██████████| 29/29 [00:03<00:00,  9.32it/s]\n",
      "Folder 201/400 - blujay: 100%|██████████| 84/84 [00:07<00:00, 10.55it/s]\n",
      "Folder 202/400 - yeteup1: 100%|██████████| 15/15 [00:01<00:00, 10.60it/s]\n",
      "Folder 203/400 - banwre1: 100%|██████████| 38/38 [00:04<00:00,  7.98it/s]\n",
      "Folder 204/400 - sccsun2: 100%|██████████| 24/24 [00:01<00:00, 15.89it/s]\n",
      "Folder 205/400 - blhori1: 100%|██████████| 62/62 [00:04<00:00, 14.84it/s]\n",
      "Folder 206/400 - lazbun: 100%|██████████| 22/22 [00:03<00:00,  5.91it/s]\n",
      "Folder 207/400 - grnher: 100%|██████████| 19/19 [00:01<00:00, 13.13it/s]\n",
      "Folder 208/400 - plupig2: 100%|██████████| 47/47 [00:05<00:00,  8.21it/s]\n",
      "Folder 209/400 - blacuc1: 100%|██████████| 16/16 [00:01<00:00, 11.21it/s]\n",
      "Folder 210/400 - bladro1: 100%|██████████| 31/31 [00:03<00:00,  9.13it/s]\n",
      "Folder 211/400 - whtspa: 100%|██████████| 40/40 [00:07<00:00,  5.68it/s]\n",
      "Folder 212/400 - yefcan: 100%|██████████| 13/13 [00:00<00:00, 14.01it/s]\n",
      "Folder 213/400 - herwar: 100%|██████████| 13/13 [00:02<00:00,  6.16it/s]\n",
      "Folder 214/400 - canwre: 100%|██████████| 39/39 [00:05<00:00,  7.58it/s]\n",
      "Folder 215/400 - revbul: 100%|██████████| 21/21 [00:02<00:00,  8.47it/s]\n",
      "Folder 216/400 - cibwar1: 100%|██████████| 22/22 [00:01<00:00, 11.79it/s]\n",
      "Folder 217/400 - wookin1: 100%|██████████| 11/11 [00:00<00:00, 19.99it/s]\n",
      "Folder 218/400 - hutvir: 100%|██████████| 32/32 [00:03<00:00,  9.37it/s]\n",
      "Folder 219/400 - lotman1: 100%|██████████| 12/12 [00:01<00:00,  6.82it/s]\n",
      "Folder 220/400 - colcha1: 100%|██████████| 16/16 [00:02<00:00,  5.95it/s]\n",
      "Folder 221/400 - daejun: 100%|██████████| 64/64 [00:08<00:00,  7.28it/s]\n",
      "Folder 222/400 - reccar: 100%|██████████| 17/17 [00:01<00:00, 11.65it/s]\n",
      "Folder 223/400 - colsun2: 100%|██████████| 25/25 [00:01<00:00, 12.63it/s]\n",
      "Folder 224/400 - norcar: 100%|██████████| 124/124 [00:14<00:00,  8.56it/s]\n",
      "Folder 225/400 - cregos1: 100%|██████████| 21/21 [00:03<00:00,  5.74it/s]\n",
      "Folder 226/400 - cocwoo1: 100%|██████████| 12/12 [00:01<00:00,  9.27it/s]\n",
      "Folder 227/400 - horlar: 100%|██████████| 35/35 [00:04<00:00,  7.20it/s]\n",
      "Folder 228/400 - pitwhy: 100%|██████████| 13/13 [00:00<00:00, 14.81it/s]\n",
      "Folder 229/400 - yebsap: 100%|██████████| 14/14 [00:01<00:00, 11.16it/s]\n",
      "Folder 230/400 - soufis1: 100%|██████████| 12/12 [00:01<00:00,  7.84it/s]\n",
      "Folder 231/400 - chbchi: 100%|██████████| 11/11 [00:01<00:00,  7.20it/s]\n",
      "Folder 232/400 - savspa: 100%|██████████| 59/59 [00:08<00:00,  6.68it/s]\n",
      "Folder 233/400 - coohaw: 100%|██████████| 17/17 [00:02<00:00,  8.08it/s]\n",
      "Folder 234/400 - rugdov: 100%|██████████| 10/10 [00:00<00:00, 11.51it/s]\n",
      "Folder 235/400 - yehbla: 100%|██████████| 23/23 [00:04<00:00,  5.62it/s]\n",
      "Folder 236/400 - olsfly: 100%|██████████| 12/12 [00:01<00:00,  8.18it/s]\n",
      "Folder 237/400 - norwat: 100%|██████████| 42/42 [00:06<00:00,  6.95it/s]\n",
      "Folder 238/400 - pabflo1: 100%|██████████| 17/17 [00:01<00:00, 10.48it/s]\n",
      "Folder 239/400 - clanut: 100%|██████████| 19/19 [00:02<00:00,  8.06it/s]\n",
      "Folder 240/400 - gocfly1: 100%|██████████| 33/33 [00:02<00:00, 11.75it/s]\n",
      "Folder 241/400 - westan: 100%|██████████| 24/24 [00:04<00:00,  5.98it/s]\n",
      "Folder 242/400 - bobfly1: 100%|██████████| 42/42 [00:03<00:00, 11.76it/s]\n",
      "Folder 243/400 - lirplo: 100%|██████████| 153/153 [00:09<00:00, 15.32it/s]\n",
      "Folder 244/400 - carcha1: 100%|██████████| 16/16 [00:01<00:00,  8.26it/s]\n",
      "Folder 245/400 - brespa: 100%|██████████| 38/38 [00:07<00:00,  5.40it/s]\n",
      "Folder 246/400 - shicow: 100%|██████████| 27/27 [00:02<00:00, 10.48it/s]\n",
      "Folder 247/400 - ashpri1: 100%|██████████| 21/21 [00:01<00:00, 15.15it/s]\n",
      "Folder 248/400 - rumfly1: 100%|██████████| 38/38 [00:03<00:00, 12.09it/s]\n",
      "Folder 249/400 - indpit1: 100%|██████████| 21/21 [00:01<00:00, 11.69it/s]\n",
      "Folder 250/400 - parjae: 100%|██████████| 17/17 [00:01<00:00, 13.05it/s]\n",
      "Folder 251/400 - lewduc1: 100%|██████████| 13/13 [00:01<00:00, 11.06it/s]\n",
      "Folder 252/400 - paltan1: 100%|██████████| 26/26 [00:01<00:00, 13.22it/s]\n",
      "Folder 253/400 - oaktit: 100%|██████████| 22/22 [00:03<00:00,  6.50it/s]\n",
      "Folder 254/400 - sthant1: 100%|██████████| 30/30 [00:02<00:00, 10.14it/s]\n",
      "Folder 255/400 - whiter: 100%|██████████| 11/11 [00:00<00:00, 20.34it/s]\n",
      "Folder 256/400 - spoowl1: 100%|██████████| 18/18 [00:01<00:00, 15.41it/s]\n",
      "Folder 257/400 - comsan: 100%|██████████| 209/209 [00:17<00:00, 12.16it/s]\n",
      "Folder 258/400 - wewpew: 100%|██████████| 36/36 [00:04<00:00,  8.56it/s]\n",
      "Folder 259/400 - asikoe2: 100%|██████████| 107/107 [00:07<00:00, 13.45it/s]\n",
      "Folder 260/400 - whbbul2: 100%|██████████| 14/14 [00:00<00:00, 15.90it/s]\n",
      "Folder 261/400 - plapri1: 100%|██████████| 43/43 [00:02<00:00, 15.40it/s]\n",
      "Folder 262/400 - grbher3: 100%|██████████| 31/31 [00:02<00:00, 14.94it/s]\n",
      "Folder 263/400 - houwre: 100%|██████████| 250/250 [00:20<00:00, 12.21it/s]\n",
      "Folder 264/400 - bongul: 100%|██████████| 13/13 [00:00<00:00, 15.35it/s]\n",
      "Folder 265/400 - yefgra1: 100%|██████████| 14/14 [00:00<00:00, 17.09it/s]\n",
      "Folder 266/400 - killde: 100%|██████████| 50/50 [00:03<00:00, 16.25it/s]\n",
      "Folder 267/400 - blhpar1: 100%|██████████| 31/31 [00:01<00:00, 19.61it/s]\n",
      "Folder 268/400 - royter1: 100%|██████████| 21/21 [00:01<00:00, 13.66it/s]\n",
      "Folder 269/400 - grtdro1: 100%|██████████| 88/88 [00:05<00:00, 15.17it/s]\n",
      "Folder 270/400 - goowoo1: 100%|██████████| 14/14 [00:00<00:00, 25.36it/s]\n",
      "Folder 271/400 - grywag: 100%|██████████| 99/99 [00:04<00:00, 23.50it/s]\n",
      "Folder 272/400 - gobbun1: 100%|██████████| 17/17 [00:00<00:00, 17.21it/s]\n",
      "Folder 273/400 - blnmon1: 100%|██████████| 48/48 [00:02<00:00, 21.95it/s]\n",
      "Folder 274/400 - comloo: 100%|██████████| 10/10 [00:00<00:00, 12.23it/s]\n",
      "Folder 275/400 - houspa: 100%|██████████| 276/276 [00:22<00:00, 12.34it/s]\n",
      "Folder 276/400 - crbsun2: 100%|██████████| 12/12 [00:00<00:00, 16.49it/s]\n",
      "Folder 277/400 - bkskit1: 100%|██████████| 67/67 [00:05<00:00, 12.31it/s]\n",
      "Folder 278/400 - wooscj2: 100%|██████████| 23/23 [00:02<00:00, 11.39it/s]\n",
      "Folder 279/400 - aldfly: 100%|██████████| 10/10 [00:01<00:00,  8.47it/s]\n",
      "Folder 280/400 - thrnig1: 100%|██████████| 121/121 [00:20<00:00,  5.79it/s]\n",
      "Folder 281/400 - purgal2: 100%|██████████| 17/17 [00:00<00:00, 23.46it/s]\n",
      "Folder 282/400 - redcro: 100%|██████████| 284/284 [00:25<00:00, 10.92it/s]\n",
      "Folder 283/400 - cobtan1: 100%|██████████| 26/26 [00:02<00:00, 12.13it/s]\n",
      "Folder 284/400 - laugul: 100%|██████████| 33/33 [00:02<00:00, 15.74it/s]\n",
      "Folder 285/400 - rewbul: 100%|██████████| 53/53 [00:04<00:00, 11.44it/s]\n",
      "Folder 286/400 - gycwar3: 100%|██████████| 16/16 [00:00<00:00, 19.22it/s]\n",
      "Folder 287/400 - louwat: 100%|██████████| 11/11 [00:00<00:00, 11.20it/s]\n",
      "Folder 288/400 - gyhcaf1: 100%|██████████| 77/77 [00:05<00:00, 15.19it/s]\n",
      "Folder 289/400 - azaspi1: 100%|██████████| 72/72 [00:04<00:00, 16.88it/s]\n",
      "Folder 290/400 - eurwig:  93%|█████████▎| 51/55 [00:03<00:00, 16.01it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      5\u001b[39m sample_rate = \u001b[32m32000\u001b[39m\n\u001b[32m      7\u001b[39m reset_seed()\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m folder_df = \u001b[43mget_random_folders_filtered\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbase_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m    \u001b[49m\u001b[43msplit_interval_secs\u001b[49m\u001b[43m=\u001b[49m\u001b[43msplit_interval_secs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m     12\u001b[39m \u001b[43m    \u001b[49m\u001b[43msample_rate\u001b[49m\u001b[43m=\u001b[49m\u001b[43msample_rate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtotal_folders\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m400\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmin_rating\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m5.0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     15\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_files_per_folder\u001b[49m\u001b[43m=\u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m1\u001b[39;49m\n\u001b[32m     16\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 44\u001b[39m, in \u001b[36mget_random_folders_filtered\u001b[39m\u001b[34m(base_dir, split_interval_secs, sample_rate, total_folders, max_files_per_folder, min_rating)\u001b[39m\n\u001b[32m     41\u001b[39m \u001b[38;5;66;03m# iterate through each file in the folder\u001b[39;00m\n\u001b[32m     42\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m file_path \u001b[38;5;129;01min\u001b[39;00m (progress_bar := tqdm(valid_folder_files)):\n\u001b[32m     43\u001b[39m     \u001b[38;5;66;03m# load file data and resample to sample_rate if necessary\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m44\u001b[39m     file_data, file_sample_rate_hz = \u001b[43mtorchaudio\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43muri\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchannels_first\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     45\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m file_sample_rate_hz != sample_rate:\n\u001b[32m     46\u001b[39m         file_data = torchaudio.functional.resample(file_data, orig_freq=file_sample_rate_hz, new_freq=sample_rate)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\bradl\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torchaudio\\_backend\\utils.py:222\u001b[39m, in \u001b[36mget_load_func.<locals>.load\u001b[39m\u001b[34m(uri, frame_offset, num_frames, normalize, channels_first, format, buffer_size, backend)\u001b[39m\n\u001b[32m    213\u001b[39m warnings.warn(\n\u001b[32m    214\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mIn 2.9, this function\u001b[39m\u001b[33m'\u001b[39m\u001b[33ms implementation will be changed to use \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    215\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mtorchaudio.load_with_torchcodec` under the hood. Some \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m    219\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mhttps://docs.pytorch.org/torchcodec/stable/generated/torchcodec.decoders.AudioDecoder.html#torchcodec.decoders.AudioDecoder.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    220\u001b[39m )\n\u001b[32m    221\u001b[39m backend = dispatcher(uri, \u001b[38;5;28mformat\u001b[39m, backend)\n\u001b[32m--> \u001b[39m\u001b[32m222\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbackend\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43muri\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframe_offset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_frames\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnormalize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchannels_first\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer_size\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\bradl\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torchaudio\\_backend\\soundfile.py:27\u001b[39m, in \u001b[36mSoundfileBackend.load\u001b[39m\u001b[34m(uri, frame_offset, num_frames, normalize, channels_first, format, buffer_size)\u001b[39m\n\u001b[32m     17\u001b[39m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[32m     18\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mload\u001b[39m(\n\u001b[32m     19\u001b[39m     uri: Union[BinaryIO, \u001b[38;5;28mstr\u001b[39m, os.PathLike],\n\u001b[32m   (...)\u001b[39m\u001b[32m     25\u001b[39m     buffer_size: \u001b[38;5;28mint\u001b[39m = \u001b[32m4096\u001b[39m,\n\u001b[32m     26\u001b[39m ) -> Tuple[torch.Tensor, \u001b[38;5;28mint\u001b[39m]:\n\u001b[32m---> \u001b[39m\u001b[32m27\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msoundfile_backend\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43muri\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframe_offset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_frames\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnormalize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchannels_first\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\bradl\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torchaudio\\_backend\\soundfile_backend.py:221\u001b[39m, in \u001b[36mload\u001b[39m\u001b[34m(filepath, frame_offset, num_frames, normalize, channels_first, format)\u001b[39m\n\u001b[32m    139\u001b[39m \u001b[38;5;129m@_requires_soundfile\u001b[39m\n\u001b[32m    140\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mload\u001b[39m(\n\u001b[32m    141\u001b[39m     filepath: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    146\u001b[39m     \u001b[38;5;28mformat\u001b[39m: Optional[\u001b[38;5;28mstr\u001b[39m] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    147\u001b[39m ) -> Tuple[torch.Tensor, \u001b[38;5;28mint\u001b[39m]:\n\u001b[32m    148\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Load audio data from file.\u001b[39;00m\n\u001b[32m    149\u001b[39m \n\u001b[32m    150\u001b[39m \u001b[33;03m    Note:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    219\u001b[39m \u001b[33;03m            `[channel, time]` else `[time, channel]`.\u001b[39;00m\n\u001b[32m    220\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m221\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43msoundfile\u001b[49m\u001b[43m.\u001b[49m\u001b[43mSoundFile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mr\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m file_:\n\u001b[32m    222\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m file_.format != \u001b[33m\"\u001b[39m\u001b[33mWAV\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m normalize:\n\u001b[32m    223\u001b[39m             dtype = \u001b[33m\"\u001b[39m\u001b[33mfloat32\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\bradl\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\soundfile.py:690\u001b[39m, in \u001b[36mSoundFile.__init__\u001b[39m\u001b[34m(self, file, mode, samplerate, channels, subtype, endian, format, closefd, compression_level, bitrate_mode)\u001b[39m\n\u001b[32m    687\u001b[39m \u001b[38;5;28mself\u001b[39m._bitrate_mode = bitrate_mode\n\u001b[32m    688\u001b[39m \u001b[38;5;28mself\u001b[39m._info = _create_info_struct(file, mode, samplerate, channels,\n\u001b[32m    689\u001b[39m                                  \u001b[38;5;28mformat\u001b[39m, subtype, endian)\n\u001b[32m--> \u001b[39m\u001b[32m690\u001b[39m \u001b[38;5;28mself\u001b[39m._file = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode_int\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclosefd\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    691\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mset\u001b[39m(mode).issuperset(\u001b[33m'\u001b[39m\u001b[33mr+\u001b[39m\u001b[33m'\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.seekable():\n\u001b[32m    692\u001b[39m     \u001b[38;5;66;03m# Move write position to 0 (like in Python file objects)\u001b[39;00m\n\u001b[32m    693\u001b[39m     \u001b[38;5;28mself\u001b[39m.seek(\u001b[32m0\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\bradl\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\soundfile.py:1254\u001b[39m, in \u001b[36mSoundFile._open\u001b[39m\u001b[34m(self, file, mode_int, closefd)\u001b[39m\n\u001b[32m   1252\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1253\u001b[39m             file = file.encode(_sys.getfilesystemencoding())\n\u001b[32m-> \u001b[39m\u001b[32m1254\u001b[39m     file_ptr = \u001b[43mopenfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode_int\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_info\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1255\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(file, \u001b[38;5;28mint\u001b[39m):\n\u001b[32m   1256\u001b[39m     file_ptr = _snd.sf_open_fd(file, mode_int, \u001b[38;5;28mself\u001b[39m._info, closefd)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# base_dir = \"/mnt/lustre/peprmint/train_audio/\"\n",
    "base_dir = \"../datasets/birdsongs-combined/train_audio/\"\n",
    "\n",
    "split_interval_secs = 2\n",
    "sample_rate = 32000\n",
    "\n",
    "reset_seed()\n",
    "\n",
    "folder_df = get_random_folders_filtered(\n",
    "    base_dir, \n",
    "    split_interval_secs=split_interval_secs, \n",
    "    sample_rate=sample_rate,\n",
    "    total_folders=400,\n",
    "    min_rating=5.0,\n",
    "    max_files_per_folder=-1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_df[\"mel_spec_shape\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-15T01:26:54.513665Z",
     "iopub.status.busy": "2025-12-15T01:26:54.513041Z",
     "iopub.status.idle": "2025-12-15T01:26:54.522503Z",
     "shell.execute_reply": "2025-12-15T01:26:54.522194Z",
     "shell.execute_reply.started": "2025-12-15T01:26:54.513650Z"
    }
   },
   "outputs": [],
   "source": [
    "for name, value in list(locals().items()):\n",
    "    if name == \"folder_df\":\n",
    "        print(name, sys.getsizeof(value) / 1024 ** 2, \"GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-15T01:26:54.525040Z",
     "iopub.status.busy": "2025-12-15T01:26:54.524420Z",
     "iopub.status.idle": "2025-12-15T01:26:54.528142Z",
     "shell.execute_reply": "2025-12-15T01:26:54.527805Z",
     "shell.execute_reply.started": "2025-12-15T01:26:54.525025Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"sound clips BEFORE any sampling:\", len(folder_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-15T01:26:54.529707Z",
     "iopub.status.busy": "2025-12-15T01:26:54.529083Z",
     "iopub.status.idle": "2025-12-15T01:26:54.540769Z",
     "shell.execute_reply": "2025-12-15T01:26:54.540439Z",
     "shell.execute_reply.started": "2025-12-15T01:26:54.529693Z"
    },
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "len(folder_df[\"folder\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-15T01:26:54.542547Z",
     "iopub.status.busy": "2025-12-15T01:26:54.541850Z",
     "iopub.status.idle": "2025-12-15T01:26:54.684981Z",
     "shell.execute_reply": "2025-12-15T01:26:54.684664Z",
     "shell.execute_reply.started": "2025-12-15T01:26:54.542533Z"
    },
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "folder_df[\"folder\"].value_counts().plot.bar(title=\"Value counts before over/under sampling.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-15T01:26:54.686574Z",
     "iopub.status.busy": "2025-12-15T01:26:54.685987Z",
     "iopub.status.idle": "2025-12-15T01:26:54.716976Z",
     "shell.execute_reply": "2025-12-15T01:26:54.716617Z",
     "shell.execute_reply.started": "2025-12-15T01:26:54.686560Z"
    }
   },
   "outputs": [],
   "source": [
    "# apply random undersampling OR oversampling\n",
    "\n",
    "sampling_technique = \"median\"\n",
    "\n",
    "reset_seed()\n",
    "\n",
    "if sampling_technique == \"under\":\n",
    "    # random \"naive\" undersampling\n",
    "    # delete random rows from all classes except minority class(es)\n",
    "    min_folder_count = min(folder_df[\"folder\"].value_counts())\n",
    "\n",
    "    indices_to_keep = np.array([])\n",
    "\n",
    "    for f in folder_df[\"folder\"].unique():\n",
    "        indices_to_keep = np.concat([np.random.choice(folder_df[folder_df[\"folder\"] == f].index, size=min_folder_count), indices_to_keep])\n",
    "\n",
    "    folder_df = folder_df.loc[indices_to_keep]\n",
    "    folder_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "if sampling_technique == \"over\":\n",
    "    ros = RandomOverSampler(random_state=1368)\n",
    "\n",
    "    # print how much each class will increase by (relative to its current size)\n",
    "    max_folder = max(folder_df[\"folder\"].value_counts())\n",
    "    for folder, count in folder_df[\"folder\"].value_counts().sort_values(ascending=True).items():\n",
    "        print(f\"{folder} will increase by {round((max_folder / count - 1) * 100, 2)}%\")\n",
    "\n",
    "    folder_df = pd.concat(ros.fit_resample(folder_df.drop(\"folder\", axis=1), folder_df[\"folder\"]), axis=1)\n",
    "    # moves \"folder\" to other side of df but shouldn't affect anything\n",
    "\n",
    "if sampling_technique == \"median\":\n",
    "    # take the median value of folder counts\n",
    "    # under sample all above the median\n",
    "    # over smaple all below the median\n",
    "\n",
    "    ros = RandomOverSampler(random_state=1368)\n",
    "    median_folder_count = round(folder_df[\"folder\"].value_counts().median())\n",
    "    indices_to_keep = np.array([])\n",
    "\n",
    "    print(\"median:\", median_folder_count)\n",
    "\n",
    "    for f in folder_df[\"folder\"].unique():\n",
    "        folder_length = len(folder_df[folder_df[\"folder\"] == f])\n",
    "        if folder_length > median_folder_count:\n",
    "            indices_to_keep = np.concat([np.random.choice(folder_df[folder_df[\"folder\"] == f].index, size=median_folder_count), indices_to_keep])\n",
    "        else:\n",
    "            indices_to_keep = np.concat([folder_df[folder_df[\"folder\"] == f].index, indices_to_keep])\n",
    "        \n",
    "    folder_df = folder_df.loc[indices_to_keep]\n",
    "    folder_df.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    folder_df = pd.concat(ros.fit_resample(folder_df.drop(\"folder\", axis=1), folder_df[\"folder\"]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-15T01:26:54.717637Z",
     "iopub.status.busy": "2025-12-15T01:26:54.717388Z",
     "iopub.status.idle": "2025-12-15T01:26:54.806771Z",
     "shell.execute_reply": "2025-12-15T01:26:54.806485Z",
     "shell.execute_reply.started": "2025-12-15T01:26:54.717624Z"
    }
   },
   "outputs": [],
   "source": [
    "folder_df[\"folder\"].value_counts().plot.bar(title=f\"Value counts after {sampling_technique} sampling.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-15T01:26:54.807320Z",
     "iopub.status.busy": "2025-12-15T01:26:54.807193Z",
     "iopub.status.idle": "2025-12-15T01:26:54.809786Z",
     "shell.execute_reply": "2025-12-15T01:26:54.809466Z",
     "shell.execute_reply.started": "2025-12-15T01:26:54.807308Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"sound clips AFTER sampling:\", len(folder_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-15T01:28:48.911497Z",
     "iopub.status.busy": "2025-12-15T01:28:48.911232Z",
     "iopub.status.idle": "2025-12-15T01:28:49.287199Z",
     "shell.execute_reply": "2025-12-15T01:28:49.286895Z",
     "shell.execute_reply.started": "2025-12-15T01:28:48.911481Z"
    },
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# plot 5 random mel spectrograms\n",
    "# checks for consistency in scaling and whatnot\n",
    "\n",
    "reset_seed()\n",
    "\n",
    "sample_spec_indices = random.sample(folder_df.index.tolist(), k=3)\n",
    "\n",
    "for i in sample_spec_indices:\n",
    "    row = folder_df.iloc[i]\n",
    "    \n",
    "    print(row[\"mel_spec_shape\"])\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.imshow(row[\"mel_spec\"])\n",
    "    plt.title(f\"Mel-Spectrogram of {'/'.join(row['file'].split('/')[-2:])}\")\n",
    "    plt.colorbar(format='%+2.0f dB')\n",
    "    plt.show()\n",
    "\n",
    "del row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-15T01:26:55.653524Z",
     "iopub.status.busy": "2025-12-15T01:26:55.653393Z",
     "iopub.status.idle": "2025-12-15T01:26:55.655541Z",
     "shell.execute_reply": "2025-12-15T01:26:55.655159Z",
     "shell.execute_reply.started": "2025-12-15T01:26:55.653512Z"
    },
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# mel_spec_shape's x value is ALWAYS 128."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-15T01:26:55.656040Z",
     "iopub.status.busy": "2025-12-15T01:26:55.655862Z",
     "iopub.status.idle": "2025-12-15T01:26:55.663818Z",
     "shell.execute_reply": "2025-12-15T01:26:55.663532Z",
     "shell.execute_reply.started": "2025-12-15T01:26:55.656027Z"
    },
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "folder_df[[\"file_length_secs\", \"mel_spec_shape\"]].value_counts()\n",
    "\n",
    "# all of the same shape WHEN:\n",
    "# - all file lengths are the same (customise interval at will)\n",
    "# - sample rate is controlled. (e.g. 32000hz)\n",
    "\n",
    "# 10 second file length + 32000 sampling rate = (128, 626) input shape\n",
    "# 2 second file length + 32000 sampling rate = (128, 126) input shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-15T01:26:55.664286Z",
     "iopub.status.busy": "2025-12-15T01:26:55.664163Z",
     "iopub.status.idle": "2025-12-15T01:26:55.932961Z",
     "shell.execute_reply": "2025-12-15T01:26:55.932560Z",
     "shell.execute_reply.started": "2025-12-15T01:26:55.664274Z"
    },
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# input shape needs to be AxBxCxD\n",
    "# A = list of files\n",
    "# B = depth of each one (currently just 1, as it only contains 1 value. if colours are used then maybe up it to 3)\n",
    "# CxD = input width/height (128x626 etc)\n",
    "\n",
    "x = torch.from_numpy(np.stack(folder_df[\"mel_spec\"].values))\n",
    "x = x.reshape(x.shape[0], 1, x.shape[1], x.shape[2])\n",
    "x = x.to(device)\n",
    "\n",
    "le = LabelEncoder()\n",
    "y = torch.LongTensor(le.fit_transform(folder_df[\"folder\"]))\n",
    "y = y.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-15T01:26:55.933551Z",
     "iopub.status.busy": "2025-12-15T01:26:55.933426Z",
     "iopub.status.idle": "2025-12-15T01:26:55.951409Z",
     "shell.execute_reply": "2025-12-15T01:26:55.951122Z",
     "shell.execute_reply.started": "2025-12-15T01:26:55.933538Z"
    },
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "reset_seed()\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, shuffle=True, test_size=0.2, random_state=1368)\n",
    "\n",
    "del x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-15T01:26:55.951983Z",
     "iopub.status.busy": "2025-12-15T01:26:55.951856Z",
     "iopub.status.idle": "2025-12-15T01:26:55.956322Z",
     "shell.execute_reply": "2025-12-15T01:26:55.955999Z",
     "shell.execute_reply.started": "2025-12-15T01:26:55.951971Z"
    },
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# create machine learning model.\n",
    "\n",
    "class TestModel(nn.Module):\n",
    "    global folder_df\n",
    "\n",
    "    def __init__(self, input_shape: torch.Size, dropout_rate: float = 0):\n",
    "        super().__init__()\n",
    "\n",
    "        total_output_classes = len(folder_df[\"folder\"].unique())\n",
    "\n",
    "        # input shape should be some list/tuple of length 4\n",
    "        if len(input_shape) != 4: return Exception(\"Input shape is not AxBxCxD.\")\n",
    "\n",
    "        # define layers here\n",
    "        # assuming input shape = 1x1x128x126 = AxBxCxD\n",
    "\n",
    "        # conv2d: 1x128x126 -> 1x124x124 (kernel size = (5,3))\n",
    "        # relu\n",
    "        # max pool: 1x124x124 -> 1x62x62 (pool size = (2,2))\n",
    "        # conv2d: 1x62x62 -> 1x60x60 (kernel size = (3, 3))\n",
    "        # relu\n",
    "        # max pool: 1x60x60 -> 1x30x30 (pool size = (2, 2))\n",
    "        # flatten: 1x30x30 -> 900\n",
    "        # linear: 900 -> 128\n",
    "        # linear: 128 -> 32\n",
    "        # linear: 32 -> (output layers)\n",
    "\n",
    "        A = input_shape[0]\n",
    "        B = input_shape[1]\n",
    "        C = input_shape[2]\n",
    "        D = input_shape[3]\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels=B, out_channels=1, kernel_size=(5, 3)) # output shape = Ax1x(C-4)x(D-2)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2) # output shape = Ax1x(C-4 // 2)x(D-2 // 2)\n",
    "        self.drop1 = nn.Dropout(p=dropout_rate)\n",
    "        self.conv2 = nn.Conv2d(in_channels=1, out_channels=1, kernel_size=(3, 3)) # output shape = Ax1x(C - 4 // 2 - 2)x(D - 2 // 2 - 2)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2) # output shape = Ax1x([(C - 4) // 2 - 2] // 2)x([(D - 2) // 2] - 2] // 2) idk the bracket order\n",
    "        self.drop2 = nn.Dropout(p=dropout_rate)\n",
    "        self.flat = nn.Flatten()\n",
    "\n",
    "        flatten_nodes = ((((C - 4) // 2) - 2) // 2) * ((((D - 2) // 2) - 2) // 2)\n",
    "        \n",
    "        self.linear1 = nn.Linear(in_features=flatten_nodes, out_features=128)\n",
    "        self.linear2 = nn.Linear(in_features=128, out_features=32) \n",
    "        self.output = nn.Linear(in_features=32, out_features=total_output_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # define calculations here\n",
    "        x = self.relu1(self.conv1(x))\n",
    "        x = self.pool1(x)\n",
    "        x = self.drop1(x)\n",
    "        x = self.relu2(self.conv2(x))\n",
    "        x = self.pool2(x)\n",
    "        x = self.drop2(x)\n",
    "        x = self.flat(x)\n",
    "        x = self.linear1(x)\n",
    "        x = self.linear2(x)\n",
    "        x = self.output(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-15T01:26:55.956813Z",
     "iopub.status.busy": "2025-12-15T01:26:55.956685Z",
     "iopub.status.idle": "2025-12-15T01:26:55.961879Z",
     "shell.execute_reply": "2025-12-15T01:26:55.961536Z",
     "shell.execute_reply.started": "2025-12-15T01:26:55.956801Z"
    },
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "def train_model(model, loss_fn, optimizer, epochs, batch_size, save_best_to_file = False):\n",
    "    batch_indices = np.linspace(0, len(x_train), int(len(x_train) / batch_size), dtype=\"int\")\n",
    "\n",
    "    train_loss_hist = []\n",
    "    train_acc_hist = []\n",
    "    test_acc_hist = []\n",
    "\n",
    "    best_test_acc = 0\n",
    "    best_model = None\n",
    "\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        model.train()\n",
    "\n",
    "        train_acc = 0\n",
    "        \n",
    "        for i in range(len(batch_indices) - 1):\n",
    "            start_index = batch_indices[i]\n",
    "            stop_index = batch_indices[i + 1]\n",
    "\n",
    "            x_batch = x_train[start_index:stop_index]\n",
    "            y_batch = y_train[start_index:stop_index]\n",
    "\n",
    "            y_pred = model(x_batch)\n",
    "            loss = loss_fn(y_pred, y_batch)\n",
    "            train_acc += sum(torch.argmax(y_pred, dim=1) == y_batch)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        train_acc = train_acc * 100 / len(y_train)\n",
    "\n",
    "        model.eval()\n",
    "        test_acc = sum(torch.argmax(model(x_test), dim=1) == y_test) * 100 / len(y_test)\n",
    "\n",
    "        print(f\"Epoch {epoch}: train loss = {loss:.04f}, train acc = {train_acc:.02f}%, test acc = {test_acc:.02f}% {\"!!\" if test_acc > best_test_acc else \"\"}\")\n",
    "\n",
    "        train_loss_hist.append(float(loss.cpu().detach().numpy()))\n",
    "        train_acc_hist.append(float(train_acc.cpu().detach().numpy()))\n",
    "        test_acc_hist.append(float(test_acc.cpu().detach().numpy()))\n",
    "\n",
    "        if test_acc > best_test_acc:\n",
    "            best_test_acc = test_acc\n",
    "            \n",
    "            # overwrite best model with new best model\n",
    "            best_model = copy.deepcopy(model.state_dict())\n",
    "\n",
    "    best_model_path = \"\"\n",
    "\n",
    "    if save_best_to_file:\n",
    "        model_save_path = \"models/\"\n",
    "\n",
    "        if not os.path.exists(model_save_path): os.mkdir(model_save_path)\n",
    "\n",
    "        file_number = len(os.listdir(model_save_path)) + 1\n",
    "\n",
    "        file_name = f\"best_model_{file_number:>03}\"\n",
    "\n",
    "        best_model_path = model_save_path + file_name + \".pth\"\n",
    "\n",
    "        torch.save(best_model, best_model_path)\n",
    "        \n",
    "\n",
    "    plt.figure(figsize=(12,8))\n",
    "    pd.Series(train_acc_hist).plot.line(label=\"Train\", color=\"blue\")\n",
    "    pd.Series(test_acc_hist).plot.line(label=\"Test\", color=\"red\")\n",
    "    plt.legend()\n",
    "    plt.ylim((0, 100))\n",
    "    plt.yticks(np.arange(0, 101, 10))\n",
    "    plt.title(f\"Convolutional Neural Network on {len(folder_df)} sound clips over {len(folder_df[\"folder\"].unique())} folders.\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Accuracy (%)\")\n",
    "    plt.grid(axis=\"y\")\n",
    "    plt.show()\n",
    "\n",
    "    return train_loss_hist, train_acc_hist, test_acc_hist, best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-15T01:26:55.962386Z",
     "iopub.status.busy": "2025-12-15T01:26:55.962265Z",
     "iopub.status.idle": "2025-12-15T01:28:07.463362Z",
     "shell.execute_reply": "2025-12-15T01:28:07.462999Z",
     "shell.execute_reply.started": "2025-12-15T01:26:55.962374Z"
    },
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# to avoid extreme overfitting:\n",
    "# - dropout rate between 0.2-0.5 seems good\n",
    "# - learning rate around 0.001 provides best training rate without overfitting\n",
    "# - train in larger batches, 64 upwards seems good\n",
    "# - most seem to plateau around 200 epochs, maybe reduce to reduce total training time\n",
    "\n",
    "reset_seed()\n",
    "\n",
    "epochs = 500\n",
    "batch_size = 64\n",
    "dropout_rate = 0\n",
    "learning_rate = 0.001\n",
    "momentum = 0\n",
    "\n",
    "model = TestModel(input_shape=x_train.shape, dropout_rate=dropout_rate)\n",
    "model = model.to(device)\n",
    "loss_fn = nn.CrossEntropyLoss() # since we are classifying.\n",
    "loss_fn = loss_fn.to(device)\n",
    "optimizer = torch.optim.AdamW(params=model.parameters(), lr=learning_rate) # adam has no momentum, but DOES have weight decay\n",
    "\n",
    "train_loss_hist, train_acc_hist, test_acc_hist, best_model = train_model(model, loss_fn, optimizer, epochs, batch_size, save_best_to_file=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-15T01:28:07.463993Z",
     "iopub.status.busy": "2025-12-15T01:28:07.463855Z",
     "iopub.status.idle": "2025-12-15T01:28:07.465947Z",
     "shell.execute_reply": "2025-12-15T01:28:07.465651Z",
     "shell.execute_reply.started": "2025-12-15T01:28:07.463980Z"
    },
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# final results after testing approx. 30 different variations of dropout, learning rate, etc\n",
    "# best learning rate = 0.001, batch size of 32/64, dropout rate around 0.2-0.5\n",
    "# 200 epochs gives best results as test acc plateaus after that, prevents overfitting\n",
    "# train/test split between 20-30% gives good results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-15T01:28:07.467436Z",
     "iopub.status.busy": "2025-12-15T01:28:07.467314Z",
     "iopub.status.idle": "2025-12-15T01:28:07.539761Z",
     "shell.execute_reply": "2025-12-15T01:28:07.539409Z",
     "shell.execute_reply.started": "2025-12-15T01:28:07.467424Z"
    }
   },
   "outputs": [],
   "source": [
    "# investigate TOP 5 ERROR of the model.\n",
    "# compare with top 1 error (accuracy)\n",
    "\n",
    "model.load_state_dict(best_model)\n",
    "model.eval()\n",
    "\n",
    "# get predictions for ALL testing data\n",
    "k = 5\n",
    "test_pred = model(x_test)\n",
    "test_pred_top_k = torch.topk(test_pred, k=k, dim=1)[1]\n",
    "\n",
    "total = 0\n",
    "in_top_k = 0\n",
    "for index, value in enumerate(y_test):\n",
    "    if value in test_pred_top_k[index]: in_top_k += 1\n",
    "\n",
    "    total += 1\n",
    "\n",
    "top_k_accuracy = in_top_k * 100 / total\n",
    "\n",
    "print(f\"Top {k} Error: {top_k_accuracy:.03f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_df[\"file\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-15T01:28:07.540254Z",
     "iopub.status.busy": "2025-12-15T01:28:07.540128Z",
     "iopub.status.idle": "2025-12-15T01:28:07.614143Z",
     "shell.execute_reply": "2025-12-15T01:28:07.613697Z",
     "shell.execute_reply.started": "2025-12-15T01:28:07.540242Z"
    }
   },
   "outputs": [],
   "source": [
    "accuracy_df = pd.DataFrame(data=[y_test.cpu().numpy(), test_pred_top_k.cpu().numpy()], index=[\"actual\", \"pred\"]).transpose()\n",
    "accuracy_df[\"in_top_5\"] = [1 if accuracy_df.iloc[i, 0] in accuracy_df.iloc[i, 1] else 0 for i in range(len(accuracy_df.index))]\n",
    "folder_top_5 = accuracy_df.groupby(by=\"actual\").aggregate(func=np.sum)[\"in_top_5\"].values\n",
    "folder_counts = accuracy_df.groupby(by=\"actual\").aggregate(func=np.size)[\"in_top_5\"].values\n",
    "accuracy_df = pd.DataFrame(data=[folder_top_5, folder_counts], index=[\"in_top_5\", \"count\"]).transpose()\n",
    "accuracy_df[\"top_5_accuracy\"] = round(accuracy_df[\"in_top_5\"] * 100 / accuracy_df[\"count\"], 2)\n",
    "accuracy_df.sort_values(by=\"top_5_accuracy\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
