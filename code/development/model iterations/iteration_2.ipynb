{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestModel(nn.Module):\n",
    "    global folder_df\n",
    "\n",
    "    def __init__(self, input_shape: torch.Size, dropout_rate: float = 0):\n",
    "        super().__init__()\n",
    "\n",
    "        total_output_classes = len(folder_df[\"folder\"].unique())\n",
    "\n",
    "        # input shape should be some list/tuple of length 4\n",
    "        if len(input_shape) != 4: return Exception(\"Input shape is not AxBxCxD.\")\n",
    "        \n",
    "        A = input_shape[0]\n",
    "        B = input_shape[1]\n",
    "        C = input_shape[2]\n",
    "        D = input_shape[3]\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels=B, out_channels=10, kernel_size=(3, 3))\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2)\n",
    "        self.drop1 = nn.Dropout(p=dropout_rate)\n",
    "        self.conv2 = nn.Conv2d(in_channels=10, out_channels=10, kernel_size=(3, 3))\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2)\n",
    "        self.drop2 = nn.Dropout(p=dropout_rate)\n",
    "        self.flat = nn.Flatten()\n",
    "\n",
    "        flatten_nodes = 10 * ((((C - 2) // 2) - 2) // 2) * ((((D - 2) // 2) - 2) // 2)\n",
    "        \n",
    "        self.norm = nn.BatchNorm1d(num_features=flatten_nodes) # not in all variations of models. technically iteration 2.1 where without this is iteration 2.0\n",
    "        self.linear1 = nn.Linear(in_features=flatten_nodes, out_features=1024)\n",
    "        self.linear2 = nn.Linear(in_features=1024, out_features=512)\n",
    "        self.linear3 = nn.Linear(in_features=512, out_features=128) \n",
    "        self.output = nn.Linear(in_features=128, out_features=total_output_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # define calculations here\n",
    "        x = self.relu1(self.conv1(x))\n",
    "        x = self.pool1(x)\n",
    "        x = self.drop1(x)\n",
    "        x = self.relu2(self.conv2(x))\n",
    "        x = self.pool2(x)\n",
    "        x = self.drop2(x)\n",
    "        x = self.flat(x)\n",
    "        x = self.norm(x)\n",
    "        x = self.linear1(x)\n",
    "        x = self.linear2(x)\n",
    "        x = self.linear3(x)\n",
    "        x = self.output(x)\n",
    "\n",
    "        return x"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
